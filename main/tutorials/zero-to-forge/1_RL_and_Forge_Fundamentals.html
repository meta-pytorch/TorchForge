
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Part 1: RL Fundamentals - Using TorchForge Terminology &#8212; torchforge 0.1 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=047068a3" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=b61afe48" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=2709fde1"></script>
    <script src="../../_static/doctools.js?v=888ff710"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script type="module" src="https://cdn.jsdelivr.net/npm/mermaid@11.2.0/dist/mermaid.esm.min.mjs"></script>
    <script type="module" src="https://cdn.jsdelivr.net/npm/@mermaid-js/layout-elk@0.1.4/dist/mermaid-layout-elk.esm.min.mjs"></script>
    <script type="module">
import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.2.0/dist/mermaid.esm.min.mjs';
mermaid.initialize({
    startOnLoad: false,
    theme: 'base',
    themeVariables: {
        primaryColor: '#4CAF50',
        primaryTextColor: '#000',
        primaryBorderColor: '#fff',
        lineColor: '#555',
        secondaryColor: '#FF9800',
        tertiaryColor: '#ffffde'
    },
    flowchart: {
        curve: 'basis'
    },
    themeCSS: '.edgePath .path { stroke-width: 4px; stroke: #555; }'
});
</script>
    <script src="https://cdn.jsdelivr.net/npm/d3@7.9.0/dist/d3.min.js"></script>
    <script type="module">
import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@11.2.0/dist/mermaid.esm.min.mjs";
window.addEventListener("load", () => mermaid.run());
</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'tutorials/zero-to-forge/1_RL_and_Forge_Fundamentals';</script>
    <script src="../../_static/custom.js?v=0065d487"></script>
    <link rel="canonical" href="https://meta-pytorch.org/torchforge/main/tutorials/zero-to-forge/1_RL_and_Forge_Fundamentals.html" />
    <link rel="icon" href="../../_static/logo-icon.svg"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Part 2: Peeling Back the Abstraction - What Are Services?" href="2_Forge_Internals.html" />
    <link rel="prev" title="Zero to TorchForge: From RL Theory to Production-Scale Implementation" href="../../zero-to-forge-intro.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects
  document.addEventListener('DOMContentLoaded', function () {
    // Hide cookie banner on local environments and LF owned docs
    if (window.location.hostname === 'localhost' ||
      window.location.hostname === '0.0.0.0' ||
      window.location.hostname === '127.0.0.1' ||
      window.location.hostname === 'docs.pytorch.org' ||
      window.location.hostname === 'docs-preview.pytorch.org' ||
      window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<!-- Conditional CSS for header and footer height adjustment -->

<style>
  :root {
    --header-height: 0px !important;
    --header-height-desktop: 0px !important;
  }
</style>


<style>
  @media (min-width: 1100px) {
    .site-footer {
      height: 300px !important;
    }
  }
</style>

<link rel="stylesheet" type="text/css" href="../../_static/css/theme.css" crossorigin="anonymous">
<script type="text/javascript" src="../../_static/js/theme.js"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400&display=swap" rel="stylesheet">
<meta property="og:image" content="../../_static/img/pytorch_seo.png" />
<link rel="stylesheet" href="../../_static/webfonts/all.min.css" crossorigin="anonymous">
<meta http-equiv="Content-Security-Policy"
  content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;">
<meta name="pytorch_project" content="">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NPLPKN5G" height="0" width="0"
    style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function (w, d, s, l, i) {
    w[l] = w[l] || []; w[l].push({
      'gtm.start':
        new Date().getTime(), event: 'gtm.js'
    }); var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    j.onload = function () {
      window.dispatchEvent(new Event('gtm_loaded'));
      console.log('GTM loaded successfully');
    };
  })(window, document, 'script', 'dataLayer', 'GTM-NPLPKN5G');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
  !function (f, b, e, v, n, t, s) {
    if (f.fbq) return; n = f.fbq = function () {
      n.callMethod ?
        n.callMethod.apply(n, arguments) : n.queue.push(arguments)
    };
    if (!f._fbq) f._fbq = n; n.push = n; n.loaded = !0; n.version = '2.0';
    n.queue = []; t = b.createElement(e); t.async = !0;
    t.src = v; s = b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t, s)
  }(window, document, 'script',
    'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');
</script>
<script>
  document.documentElement.setAttribute('data-version', '');
</script>
<noscript>
  <img height="1" width="1" src="https://www.facebook.com/tr?id=243028289693773&ev=PageView&noscript=1" />
</noscript>
<script>
  function gtag() {
    window.dataLayer.push(arguments);
  }
</script>
<!-- End Facebook Pixel Code -->
<!-- Repository configuration for tutorials -->

<script>
  // Define repository configuration for tutorial buttons using existing html_context variables
  // Only injected when tutorial buttons are shown AND github variables are defined
  // If either condition is false, JavaScript will fallback to default PyTorch tutorial links
  window.repoConfig = {
    github_repo: "meta-pytorch/torchforge",
    github_branch: "main",
    colab_repo: "meta-pytorch/torchforge",
    colab_branch: "gh-pages"
  };
</script>

<!-- Script to Fix scrolling -->
<script>
  document.addEventListener('DOMContentLoaded', function () {
    // Fix anchor scrolling
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const targetId = this.getAttribute('href').substring(1);
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;
          window.scrollTo({
            top: targetPosition,
            behavior: 'smooth'
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>

<script async src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>


  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>

  </head>

<body data-feedback-url="https://github.com/meta-pytorch/forge" class="pytorch-body">
  
  
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Home</p>
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../getting_started.html">
    Getting Started
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../../tutorials.html">
    Tutorials
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api.html">
    API Reference
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
      
        <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/meta-pytorch/torchforge" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.org/" title="Discourse" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discourse</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torchforge/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../getting_started.html">
    Getting Started
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../../tutorials.html">
    Tutorials
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api.html">
    API Reference
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/meta-pytorch/torchforge" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.org/" title="Discourse" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discourse</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torchforge/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../../zero-to-forge-intro.html">Zero to TorchForge: From RL Theory to Production-Scale Implementation</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Part 1: RL Fundamentals - Using TorchForge Terminology</a></li>
<li class="toctree-l2"><a class="reference internal" href="2_Forge_Internals.html">Part 2: Peeling Back the Abstraction - What Are Services?</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_Monarch_101.html">Part 3: The TorchForge-Monarch Connection</a></li>

</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../metric_logging.html">Metric Logging in Forge</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../tutorials.html" class="nav-link">Tutorials</a></li>
    
    
    <li class="breadcrumb-item"><a href="../../zero-to-forge-intro.html" class="nav-link">Zero to TorchForge: From RL Theory to Production-Scale Implementation</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">Part 1: RL...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>
</div>
      
    </div>
  
</div>
</div>
              
              
  
<div id="searchbox"></div>
  <article class="bd-article" id="pytorch-article">
    <!-- Hidden breadcrumb schema for SEO only -->
    <div style="display:none;" itemscope itemtype="https://schema.org/BreadcrumbList">
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <link itemprop="item" href="../../tutorials.html">
        <meta itemprop="name" content="Tutorials">
        <meta itemprop="position" content="1">
      </div>
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <link itemprop="item" href="../../zero-to-forge-intro.html">
        <meta itemprop="name" content="Zero to TorchForge: From RL Theory to Production-Scale Implementation">
        <meta itemprop="position" content="2">
      </div>
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <meta itemprop="name" content="Part 1: RL Fundamentals - Using TorchForge Terminology">
        <meta itemprop="position" content="3">
      </div>
    </div>

    
    
    <div class="pytorch-call-to-action-links">
      <div id="tutorial-type">tutorials/zero-to-forge/1_RL_and_Forge_Fundamentals</div>
      <a id="colab-link" data-behavior="call-to-action-event" data-response="Run in Google Colab" target="_blank">
        <div id="google-colab-link">
          <img class="call-to-action-img" src="../../_static/img/pytorch-colab.svg" />
          <div class="call-to-action-desktop-view">Run in Google Colab</div>
          <div class="call-to-action-mobile-view">Colab</div>
        </div>
      </a>
      <a id="notebook-link" data-behavior="call-to-action-event" data-response="Download Notebook">
        <div id="download-notebook-link">
          <img class="call-to-action-notebook-img" src="../../_static/img/pytorch-download.svg" />
          <div class="call-to-action-desktop-view">Download Notebook</div>
          <div class="call-to-action-mobile-view">Notebook</div>
        </div>
      </a>
      <a id="github-link" data-behavior="call-to-action-event" data-response="View on Github" target="_blank">
        <div id="github-view-link">
          <img class="call-to-action-img" src="../../_static/img/pytorch-github.svg" />
          <div class="call-to-action-desktop-view">View on GitHub</div>
          <div class="call-to-action-mobile-view">GitHub</div>
        </div>
      </a>
    </div>
    

    
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="part-1-rl-fundamentals-using-torchforge-terminology">
<h1>Part 1: RL Fundamentals - Using TorchForge Terminology<a class="headerlink" href="#part-1-rl-fundamentals-using-torchforge-terminology" title="Link to this heading">#</a></h1>
<section id="core-rl-components-in-torchforge">
<h2>Core RL Components in TorchForge<a class="headerlink" href="#core-rl-components-in-torchforge" title="Link to this heading">#</a></h2>
<p>Let’s start with a simple math tutoring example to understand RL concepts with the exact names TorchForge uses:</p>
<section id="the-toy-example-teaching-math">
<h3>The Toy Example: Teaching Math<a class="headerlink" href="#the-toy-example-teaching-math" title="Link to this heading">#</a></h3>
<pre  class="mermaid">
        graph TD
    subgraph Example[&quot;Math Tutoring RL Example&quot;]
        Dataset[&quot;Dataset: math problems&quot;]
        Policy[&quot;Policy: student AI&quot;]
        Reward[&quot;Reward Model:
        scores answers&quot;]
        Reference[&quot;Reference Model:
        baseline&quot;]
        ReplayBuffer[&quot;Replay Buffer: stores experiences&quot;]
        Trainer[&quot;Trainer: improves student&quot;]
    end

    Dataset --&gt; Policy
    Policy --&gt; Reward
    Policy --&gt; Reference
    Reward --&gt; ReplayBuffer
    Reference --&gt; ReplayBuffer
    ReplayBuffer --&gt; Trainer
    Trainer --&gt; Policy

    style Policy fill:#4CAF50,stroke:#fff,stroke-width:2px
    style Reward fill:#FF9800,stroke:#fff,stroke-width:2px
    style Trainer fill:#E91E63,stroke:#fff,stroke-width:2px

    linkStyle default stroke:#888,stroke-width:2px
    </pre></section>
<section id="rl-components-defined-torchforge-names">
<h3>RL Components Defined (TorchForge Names)<a class="headerlink" href="#rl-components-defined-torchforge-names" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Dataset</strong>: Provides questions/prompts (like “What is 2+2?”)</p></li>
<li><p><strong>Policy</strong>: The AI being trained (generates answers like “The answer is 4”)</p></li>
<li><p><strong>Reward Model</strong>: Evaluates answer quality (gives scores like 0.95)</p></li>
<li><p><strong>Reference Model</strong>: Original policy copy (prevents drift from baseline)</p></li>
<li><p><strong>Replay Buffer</strong>: Stores experiences (question + answer + score)</p></li>
<li><p><strong>Trainer</strong>: Updates the policy weights based on experiences</p></li>
</ol>
</section>
<section id="the-rl-learning-flow">
<h3>The RL Learning Flow<a class="headerlink" href="#the-rl-learning-flow" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># CONCEPTUAL EXAMPLE - see apps/grpo/main.py for GRPO Code</span>

<span class="k">def</span><span class="w"> </span><span class="nf">conceptual_rl_step</span><span class="p">():</span>
    <span class="c1"># 1. Get a math problem</span>
    <span class="n">question</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># &quot;What is 2+2?&quot;</span>

    <span class="c1"># 2. Student generates answer</span>
    <span class="n">answer</span> <span class="o">=</span> <span class="n">policy</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">question</span><span class="p">)</span>  <span class="c1"># &quot;The answer is 4&quot;</span>

    <span class="c1"># 3. Teacher grades it</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">reward_model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">answer</span><span class="p">)</span>  <span class="c1"># 0.95</span>

    <span class="c1"># 4. Compare to original student</span>
    <span class="n">baseline</span> <span class="o">=</span> <span class="n">reference_model</span><span class="o">.</span><span class="n">compute_logprobs</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">answer</span><span class="p">)</span>

    <span class="c1"># 5. Store the experience</span>
    <span class="n">experience</span> <span class="o">=</span> <span class="n">Episode</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">answer</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">baseline</span><span class="p">)</span>
    <span class="n">replay_buffer</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">experience</span><span class="p">)</span>

    <span class="c1"># 6. When enough experiences collected, improve student</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="n">replay_buffer</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">curr_policy_version</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">batch</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">trainer</span><span class="o">.</span><span class="n">train_step</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># Student gets better!</span>

<span class="c1"># 🔄 See complete working example below with actual TorchForge service calls</span>
</pre></div>
</div>
</section>
</section>
<section id="from-concepts-to-torchforge-services">
<h2>From Concepts to TorchForge Services<a class="headerlink" href="#from-concepts-to-torchforge-services" title="Link to this heading">#</a></h2>
<p>Here’s the key insight: <strong>Each RL component becomes a TorchForge service</strong>. The toy example above maps directly to TorchForge:</p>
<pre  class="mermaid">
        graph LR
    subgraph Concepts[&quot;RL Concepts&quot;]

        C1[&quot;Dataset&quot;]
        C2[&quot;Policy&quot;]
        C3[&quot;Reward Model&quot;]
        C4[&quot;Reference Model&quot;]
        C5[&quot;Replay Buffer&quot;]
        C6[&quot;Trainer&quot;]
    end

    subgraph Services[&quot;TorchForge Services (Real Classes)&quot;]

        S1[&quot;DatasetActor&quot;]
        S2[&quot;Generator&quot;]
        S3[&quot;RewardActor&quot;]
        S4[&quot;ReferenceModel&quot;]
        S5[&quot;ReplayBuffer&quot;]
        S6[&quot;RLTrainer&quot;]
    end

    C1 --&gt; S1
    C2 --&gt; S2
    C3 --&gt; S3
    C4 --&gt; S4
    C5 --&gt; S5
    C6 --&gt; S6

    style C2 fill:#4CAF50
    style S2 fill:#4CAF50
    style C3 fill:#FF9800
    style S3 fill:#FF9800
    </pre><section id="rl-step-with-torchforge-services">
<h3>RL Step with TorchForge Services<a class="headerlink" href="#rl-step-with-torchforge-services" title="Link to this heading">#</a></h3>
<p>Let’s look at the example from above again, but this time we would use the names from TorchForge:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Conceptual Example</span>

<span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">conceptual_forge_rl_step</span><span class="p">(</span><span class="n">services</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
    <span class="c1"># 1. Get a math problem - Using actual DatasetActor API</span>
    <span class="n">sample</span> <span class="o">=</span> <span class="k">await</span> <span class="n">services</span><span class="p">[</span><span class="s1">&#39;dataloader&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sample</span><span class="o">.</span><span class="n">call_one</span><span class="p">()</span>
    <span class="n">question</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s2">&quot;request&quot;</span><span class="p">],</span> <span class="n">sample</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span>

    <span class="c1"># 2. Student generates answer - Using actual Policy API</span>
    <span class="n">responses</span> <span class="o">=</span> <span class="k">await</span> <span class="n">services</span><span class="p">[</span><span class="s1">&#39;policy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">generate</span><span class="o">.</span><span class="n">route</span><span class="p">(</span><span class="n">prompt</span><span class="o">=</span><span class="n">question</span><span class="p">)</span>
    <span class="n">answer</span> <span class="o">=</span> <span class="n">responses</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span>

    <span class="c1"># 3. Teacher grades it - Using actual RewardActor API</span>
    <span class="n">score</span> <span class="o">=</span> <span class="k">await</span> <span class="n">services</span><span class="p">[</span><span class="s1">&#39;reward_actor&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">evaluate_response</span><span class="o">.</span><span class="n">route</span><span class="p">(</span>
        <span class="n">prompt</span><span class="o">=</span><span class="n">question</span><span class="p">,</span> <span class="n">response</span><span class="o">=</span><span class="n">answer</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span>
    <span class="p">)</span>

    <span class="c1"># 4. Compare to baseline - Using actual ReferenceModel API</span>
    <span class="c1"># Note: ReferenceModel.forward requires input_ids, max_req_tokens, return_logprobs</span>
    <span class="n">ref_logprobs</span> <span class="o">=</span> <span class="k">await</span> <span class="n">services</span><span class="p">[</span><span class="s1">&#39;ref_model&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">forward</span><span class="o">.</span><span class="n">route</span><span class="p">(</span>
        <span class="n">input_ids</span><span class="p">,</span> <span class="n">max_req_tokens</span><span class="p">,</span> <span class="n">return_logprobs</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>

    <span class="c1"># 5. Store experience - Using actual Episode structure from apps/grpo/main.py</span>
    <span class="n">episode</span> <span class="o">=</span> <span class="n">create_episode_from_response</span><span class="p">(</span><span class="n">responses</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">score</span><span class="p">,</span> <span class="n">ref_logprobs</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
    <span class="k">await</span> <span class="n">services</span><span class="p">[</span><span class="s1">&#39;replay_buffer&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">add</span><span class="o">.</span><span class="n">call_one</span><span class="p">(</span><span class="n">episode</span><span class="p">)</span>

    <span class="c1"># 6. Improve student - Using actual training pattern</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="k">await</span> <span class="n">services</span><span class="p">[</span><span class="s1">&#39;replay_buffer&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sample</span><span class="o">.</span><span class="n">call_one</span><span class="p">(</span>
        <span class="n">curr_policy_version</span><span class="o">=</span><span class="n">step</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">batch</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="k">await</span> <span class="n">services</span><span class="p">[</span><span class="s1">&#39;trainer&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">train_step</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>
</pre></div>
</div>
<p><strong>Key difference</strong>: Same RL logic, but each component is now a distributed, fault-tolerant, auto-scaling service.</p>
<p>Did you realise-we are not worrying about any Infra code here! TorchForge Automagically handles the details behind the scenes and you can focus on writing your RL Algorithms!</p>
</section>
</section>
<section id="why-this-matters-traditional-ml-infrastructure-fails">
<h2>Why This Matters: Traditional ML Infrastructure Fails<a class="headerlink" href="#why-this-matters-traditional-ml-infrastructure-fails" title="Link to this heading">#</a></h2>
<section id="the-infrastructure-challenge">
<h3>The Infrastructure Challenge<a class="headerlink" href="#the-infrastructure-challenge" title="Link to this heading">#</a></h3>
<p>Our simple RL loop above has complex requirements:</p>
<section id="problem-1-different-resource-needs">
<h4>Problem 1: Different Resource Needs<a class="headerlink" href="#problem-1-different-resource-needs" title="Link to this heading">#</a></h4>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Component</p></th>
<th class="head"><p>Resource Needs</p></th>
<th class="head"><p>Scaling Strategy</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Policy</strong> (Student AI)</p></td>
<td><p>Large GPU memory</p></td>
<td><p>Multiple replicas for throughput</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Reward Heuristic</strong> (Teacher)</p></td>
<td><p>Small compute</p></td>
<td><p>CPU or small GPU</p></td>
</tr>
<tr class="row-even"><td><p><strong>Trainer</strong> (Tutor)</p></td>
<td><p>Massive GPU compute</p></td>
<td><p>Distributed training</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Dataset</strong> (Question Bank)</p></td>
<td><p>CPU intensive I/O</p></td>
<td><p>High memory bandwidth</p></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
<section id="problem-2-complex-interdependencies">
<h3>Problem 2: Complex Interdependencies<a class="headerlink" href="#problem-2-complex-interdependencies" title="Link to this heading">#</a></h3>
<pre  class="mermaid">
        graph LR
    A[&quot;Policy: Student AI
    'What is 2+2?' →
    'The answer is 4'&quot;]
    B[&quot;Reward: Teacher
    Scores answer: 0.95&quot;]
    C[&quot;Reference: Original Student
    Provides baseline comparison&quot;]
    D[&quot;Replay Buffer: Notebook
    Stores: question
    + answer
    + score&quot;]
    E[&quot;Trainer: Tutor
    Improves student
    using experiences&quot;]

    A --&gt; B
    A --&gt; C
    B --&gt; D
    C --&gt; D
    D --&gt; E
    E --&gt; A

    style A fill:#4CAF50
    style B fill:#FF9800
    style C fill:#2196F3
    style D fill:#8BC34A
    style E fill:#E91E63
    </pre><p>Each step has different:</p>
<ul class="simple">
<li><p><strong>Latency requirements</strong>: Policy inference needs low latency (each episode waits), training can batch multiple episodes together</p></li>
<li><p><strong>Scaling patterns</strong>: Need N policy replicas to keep trainer busy, plus different sharding strategies (tensor parallel for training vs replicated inference)</p></li>
<li><p><strong>Failure modes</strong>: Any component failure cascades to halt the entire pipeline (TorchForge prevents this with automatic failover)</p></li>
<li><p><strong>Resource utilization</strong>: GPUs for inference/training, CPUs for data processing</p></li>
</ul>
</section>
<section id="problem-3-the-coordination-challenge">
<h3>Problem 3: The Coordination Challenge<a class="headerlink" href="#problem-3-the-coordination-challenge" title="Link to this heading">#</a></h3>
<p>Unlike supervised learning where you process independent batches, RL requires coordination:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># While this does work, it creates bottlenecks and resource waste</span>
<span class="k">def</span><span class="w"> </span><span class="nf">naive_rl_step</span><span class="p">():</span>
    <span class="c1"># Policy waits idle while reward model works</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">policy_model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>  <span class="c1"># GPU busy</span>
    <span class="n">reward</span> <span class="o">=</span> <span class="n">reward_model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">response</span><span class="p">)</span>  <span class="c1"># Policy GPU idle</span>

    <span class="c1"># Training waits for single episode</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">compute_loss</span><span class="p">(</span><span class="n">response</span><span class="p">,</span> <span class="n">reward</span><span class="p">)</span>  <span class="c1"># Batch size = 1, inefficient</span>

    <span class="c1"># Everything stops if any component fails</span>
    <span class="k">if</span> <span class="n">policy_fails</span> <span class="ow">or</span> <span class="n">reward_fails</span> <span class="ow">or</span> <span class="n">trainer_fails</span><span class="p">:</span>
        <span class="n">entire_system_stops</span><span class="p">()</span>
</pre></div>
</div>
</section>
</section>
<section id="enter-torchforge-rl-native-architecture">
<h2>Enter TorchForge: RL-Native Architecture<a class="headerlink" href="#enter-torchforge-rl-native-architecture" title="Link to this heading">#</a></h2>
<p>TorchForge solves these problems by treating each RL component as an <strong>independent, distributed unit</strong> - some as fault-tolerant services (like Policy inference where failures are easy to handle), others as actors (like Trainers where recovery semantics differ)</p>
<p>Let’s see how core RL concepts map to TorchForge components (you’ll notice a mix of <code class="docutils literal notranslate"><span class="pre">.route()</span></code> for services and <code class="docutils literal notranslate"><span class="pre">.call_one()</span></code> for actors - we cover when to use each in Part 2):</p>
<p><strong>Quick API Reference:</strong> (covered in detail in Part 2: Service Communication Patterns)</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.route()</span></code> - Send request to any healthy replica in a service (load balanced)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.call_one()</span></code> - Send request to a single actor instance</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.fanout()</span></code> - Send request to ALL replicas in a service</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">real_rl_training_step</span><span class="p">(</span><span class="n">services</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Single RL step using verified TorchForge APIs&quot;&quot;&quot;</span>

    <span class="c1"># 1. Environment interaction - Using actual DatasetActor API</span>
    <span class="n">sample</span> <span class="o">=</span> <span class="k">await</span> <span class="n">services</span><span class="p">[</span><span class="s1">&#39;dataloader&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sample</span><span class="o">.</span><span class="n">call_one</span><span class="p">()</span>
    <span class="n">prompt</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s2">&quot;request&quot;</span><span class="p">],</span> <span class="n">sample</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span>

    <span class="n">responses</span> <span class="o">=</span> <span class="k">await</span> <span class="n">services</span><span class="p">[</span><span class="s1">&#39;policy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">generate</span><span class="o">.</span><span class="n">route</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>

    <span class="c1"># 2. Reward computation - Using actual RewardActor API</span>
    <span class="n">score</span> <span class="o">=</span> <span class="k">await</span> <span class="n">services</span><span class="p">[</span><span class="s1">&#39;reward_actor&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">evaluate_response</span><span class="o">.</span><span class="n">route</span><span class="p">(</span>
        <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span> <span class="n">response</span><span class="o">=</span><span class="n">responses</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span>
    <span class="p">)</span>

    <span class="c1"># 3. Get reference logprobs - Using actual ReferenceModel API</span>
    <span class="c1"># Note: ReferenceModel requires full input_ids tensor, not just tokens</span>
    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">responses</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">prompt_ids</span><span class="p">,</span> <span class="n">responses</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">token_ids</span><span class="p">])</span>
    <span class="n">ref_logprobs</span> <span class="o">=</span> <span class="k">await</span> <span class="n">services</span><span class="p">[</span><span class="s1">&#39;ref_model&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">forward</span><span class="o">.</span><span class="n">route</span><span class="p">(</span>
        <span class="n">input_ids</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">max_req_tokens</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">return_logprobs</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>

    <span class="c1"># 4. Experience storage - Using actual Episode pattern from GRPO</span>
    <span class="n">episode</span> <span class="o">=</span> <span class="n">create_episode_from_response</span><span class="p">(</span><span class="n">responses</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">score</span><span class="p">,</span> <span class="n">ref_logprobs</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
    <span class="k">await</span> <span class="n">services</span><span class="p">[</span><span class="s1">&#39;replay_buffer&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">add</span><span class="o">.</span><span class="n">call_one</span><span class="p">(</span><span class="n">episode</span><span class="p">)</span>

    <span class="c1"># 5. Learning - Using actual trainer pattern</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="k">await</span> <span class="n">services</span><span class="p">[</span><span class="s1">&#39;replay_buffer&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sample</span><span class="o">.</span><span class="n">call_one</span><span class="p">(</span>
        <span class="n">curr_policy_version</span><span class="o">=</span><span class="n">step</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">batch</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="n">batch</span>  <span class="c1"># GRPO returns (inputs, targets) tuple</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="k">await</span> <span class="n">services</span><span class="p">[</span><span class="s1">&#39;trainer&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">train_step</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>

        <span class="c1"># 6. Policy synchronization - Using actual weight update pattern</span>
        <span class="k">await</span> <span class="n">services</span><span class="p">[</span><span class="s1">&#39;trainer&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">push_weights</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">await</span> <span class="n">services</span><span class="p">[</span><span class="s1">&#39;policy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">update_weights</span><span class="o">.</span><span class="n">fanout</span><span class="p">(</span><span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">loss</span>
</pre></div>
</div>
<p><strong>Key insight</strong>: Each line of RL pseudocode becomes a service call. The complexity of distribution, scaling, and fault tolerance is hidden behind these simple interfaces.</p>
</section>
<section id="what-makes-this-powerful">
<h2>What Makes This Powerful<a class="headerlink" href="#what-makes-this-powerful" title="Link to this heading">#</a></h2>
<section id="automatic-resource-management">
<h3>Automatic Resource Management<a class="headerlink" href="#automatic-resource-management" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">responses</span> <span class="o">=</span> <span class="k">await</span> <span class="n">policy</span><span class="o">.</span><span class="n">generate</span><span class="o">.</span><span class="n">route</span><span class="p">(</span><span class="n">prompt</span><span class="o">=</span><span class="n">question</span><span class="p">)</span>
<span class="n">answer</span> <span class="o">=</span> <span class="n">responses</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span>  <span class="c1"># responses is list[Completion]</span>
</pre></div>
</div>
<p>TorchForge handles behind the scenes:</p>
<ul class="simple">
<li><p>Routing to least loaded replica</p></li>
<li><p>GPU memory management</p></li>
<li><p>Batch optimization</p></li>
<li><p>Failure recovery</p></li>
<li><p>Auto-scaling based on demand</p></li>
</ul>
</section>
<section id="independent-scaling">
<h3>Independent Scaling<a class="headerlink" href="#independent-scaling" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="kn">from</span><span class="w"> </span><span class="nn">forge.actors.generator</span><span class="w"> </span><span class="kn">import</span> <span class="n">Generator</span> <span class="k">as</span> <span class="n">Policy</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">forge.actors.replay_buffer</span><span class="w"> </span><span class="kn">import</span> <span class="n">ReplayBuffer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">forge.actors.reference_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">ReferenceModel</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">forge.actors.trainer</span><span class="w"> </span><span class="kn">import</span> <span class="n">RLTrainer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">apps.grpo.main</span><span class="w"> </span><span class="kn">import</span> <span class="n">DatasetActor</span><span class="p">,</span> <span class="n">RewardActor</span><span class="p">,</span> <span class="n">ComputeAdvantages</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">forge.data.rewards</span><span class="w"> </span><span class="kn">import</span> <span class="n">MathReward</span><span class="p">,</span> <span class="n">ThinkingReward</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">asyncio</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="n">model</span> <span class="o">=</span> <span class="s2">&quot;Qwen/Qwen3-1.7B&quot;</span>
<span class="n">group_size</span> <span class="o">=</span> <span class="mi">1</span>

<span class="p">(</span>
    <span class="n">dataloader</span><span class="p">,</span>
    <span class="n">policy</span><span class="p">,</span>
    <span class="n">trainer</span><span class="p">,</span>
    <span class="n">replay_buffer</span><span class="p">,</span>
    <span class="n">compute_advantages</span><span class="p">,</span>
    <span class="n">ref_model</span><span class="p">,</span>
    <span class="n">reward_actor</span><span class="p">,</span>
<span class="p">)</span> <span class="o">=</span> <span class="k">await</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span>
        <span class="c1"># Dataset actor (CPU)</span>
        <span class="n">DatasetActor</span><span class="o">.</span><span class="n">options</span><span class="p">(</span><span class="n">procs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">as_actor</span><span class="p">(</span>
            <span class="n">path</span><span class="o">=</span><span class="s2">&quot;openai/gsm8k&quot;</span><span class="p">,</span>
            <span class="n">revision</span><span class="o">=</span><span class="s2">&quot;main&quot;</span><span class="p">,</span>
            <span class="n">data_split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">,</span>
            <span class="n">streaming</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="c1"># Policy service with GPU</span>
        <span class="n">Policy</span><span class="o">.</span><span class="n">options</span><span class="p">(</span><span class="n">procs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">with_gpus</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_replicas</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">as_service</span><span class="p">(</span>
            <span class="n">engine_config</span><span class="o">=</span><span class="p">{</span>
                <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">model</span><span class="p">,</span>
                <span class="s2">&quot;tensor_parallel_size&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
                <span class="s2">&quot;pipeline_parallel_size&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
                <span class="s2">&quot;enforce_eager&quot;</span><span class="p">:</span> <span class="kc">False</span>
            <span class="p">},</span>
            <span class="n">sampling_config</span><span class="o">=</span><span class="p">{</span>
                <span class="s2">&quot;n&quot;</span><span class="p">:</span> <span class="n">group_size</span><span class="p">,</span>
                <span class="s2">&quot;max_tokens&quot;</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span>
                <span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
                <span class="s2">&quot;top_p&quot;</span><span class="p">:</span> <span class="mf">1.0</span>
            <span class="p">}</span>
        <span class="p">),</span>
        <span class="c1"># Trainer actor with GPU</span>
        <span class="n">RLTrainer</span><span class="o">.</span><span class="n">options</span><span class="p">(</span><span class="n">procs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">with_gpus</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">as_actor</span><span class="p">(</span>
            <span class="c1"># Trainer config would come from YAML in real usage</span>
            <span class="n">model</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;qwen3&quot;</span><span class="p">,</span> <span class="s2">&quot;flavor&quot;</span><span class="p">:</span> <span class="s2">&quot;1.7B&quot;</span><span class="p">,</span> <span class="s2">&quot;hf_assets_path&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;hf://</span><span class="si">{</span><span class="n">model</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">},</span>
            <span class="n">optimizer</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;AdamW&quot;</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">1e-5</span><span class="p">},</span>
            <span class="n">training</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;local_batch_size&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;seq_len&quot;</span><span class="p">:</span> <span class="mi">2048</span><span class="p">}</span>
        <span class="p">),</span>
        <span class="c1"># Replay buffer (CPU)</span>
        <span class="n">ReplayBuffer</span><span class="o">.</span><span class="n">options</span><span class="p">(</span><span class="n">procs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">as_actor</span><span class="p">(</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">max_policy_age</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">dp_size</span><span class="o">=</span><span class="mi">1</span>
        <span class="p">),</span>
        <span class="c1"># Advantage computation (CPU)</span>
        <span class="n">ComputeAdvantages</span><span class="o">.</span><span class="n">options</span><span class="p">(</span><span class="n">procs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">as_actor</span><span class="p">(),</span>
        <span class="c1"># Reference model with GPU</span>
        <span class="n">ReferenceModel</span><span class="o">.</span><span class="n">options</span><span class="p">(</span><span class="n">procs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">with_gpus</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">as_actor</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;qwen3&quot;</span><span class="p">,</span> <span class="s2">&quot;flavor&quot;</span><span class="p">:</span> <span class="s2">&quot;1.7B&quot;</span><span class="p">,</span> <span class="s2">&quot;hf_assets_path&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;hf://</span><span class="si">{</span><span class="n">model</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">},</span>
            <span class="n">training</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;dtype&quot;</span><span class="p">:</span> <span class="s2">&quot;bfloat16&quot;</span><span class="p">}</span>
        <span class="p">),</span>
        <span class="c1"># Reward actor (CPU)</span>
        <span class="n">RewardActor</span><span class="o">.</span><span class="n">options</span><span class="p">(</span><span class="n">procs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_replicas</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">as_service</span><span class="p">(</span>
            <span class="n">reward_functions</span><span class="o">=</span><span class="p">[</span><span class="n">MathReward</span><span class="p">(),</span> <span class="n">ThinkingReward</span><span class="p">()]</span>
        <span class="p">)</span>
    <span class="p">)</span>
</pre></div>
</div>
<p><strong>TorchForge Components: Services vs Actors</strong></p>
<p>TorchForge has two types of distributed components:</p>
<ul class="simple">
<li><p><strong>Services</strong>: Multiple replicas with automatic load balancing (like Policy, RewardActor)</p></li>
<li><p><strong>Actors</strong>: Single instances that handle their own internal distribution (like RLTrainer, ReplayBuffer)</p></li>
</ul>
<p>We cover this distinction in detail in Part 2, but for now this explains the scaling patterns:</p>
<ul class="simple">
<li><p>Policy service: num_replicas=8 for high inference demand</p></li>
<li><p>RewardActor service: num_replicas=16 for parallel evaluation</p></li>
<li><p>RLTrainer actor: Single instance with internal distributed training</p></li>
</ul>
</section>
<section id="fault-tolerance">
<h3>Fault Tolerance<a class="headerlink" href="#fault-tolerance" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># If a policy replica fails:</span>
<span class="n">responses</span> <span class="o">=</span> <span class="k">await</span> <span class="n">policy</span><span class="o">.</span><span class="n">generate</span><span class="o">.</span><span class="n">route</span><span class="p">(</span><span class="n">prompt</span><span class="o">=</span><span class="n">question</span><span class="p">)</span>
<span class="n">answer</span> <span class="o">=</span> <span class="n">responses</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span>
<span class="c1"># -&gt; TorchForge automatically routes to healthy replica</span>
<span class="c1"># -&gt; Failed replica respawns in background</span>
<span class="c1"># -&gt; No impact on training loop</span>

<span class="c1"># If reward service fails:</span>
<span class="n">score</span> <span class="o">=</span> <span class="k">await</span> <span class="n">reward_actor</span><span class="o">.</span><span class="n">evaluate_response</span><span class="o">.</span><span class="n">route</span><span class="p">(</span>
    <span class="n">prompt</span><span class="o">=</span><span class="n">question</span><span class="p">,</span> <span class="n">response</span><span class="o">=</span><span class="n">answer</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span>
<span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Retries on different replica automatically</p></li>
<li><p>Graceful degradation if all replicas fail</p></li>
<li><p>System continues (may need application-level handling)</p></li>
</ul>
<p>This is fundamentally different from monolithic RL implementations where any component failure stops everything!</p>
<p>In the next Section, we will go a layer deeper and learn how ForgeServices work. Continue to <a class="reference internal" href="2_Forge_Internals.html"><span class="std std-doc">Part 2 here</span></a></p>
</section>
</section>
</section>


                </article>
              
  </article>
  
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="feedback">
  
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>

  <div class="feedback-send">
    <button class="feedback-btn"
            onclick="openGitHubIssue()"
            data-bs-title="Create a GitHub Issue"
            data-bs-placement="bottom"
            data-bs-toggle="tooltip"
            data-gtm="feedback-btn-click">Send Feedback
    </button>
  </div>
</div>

<div class="prev-next-area">
    <a class="left-prev"
       href="../../zero-to-forge-intro.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Zero to TorchForge: From RL Theory to Production-Scale Implementation</p>
      </div>
    </a>
    <a class="right-next"
       href="2_Forge_Internals.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Part 2: Peeling Back the Abstraction - What Are Services?</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>

<div class="footer-info">
  <p class="copyright">
    
  </p>

  <p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
  
</div>
                </footer>
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../../zero-to-forge-intro.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Zero to TorchForge: From RL Theory to Production-Scale Implementation</p>
      </div>
    </a>
    <a class="right-next"
       href="2_Forge_Internals.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Part 2: Peeling Back the Abstraction - What Are Services?</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
    
       <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#core-rl-components-in-torchforge">Core RL Components in TorchForge</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-toy-example-teaching-math">The Toy Example: Teaching Math</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#rl-components-defined-torchforge-names">RL Components Defined (TorchForge Names)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-rl-learning-flow">The RL Learning Flow</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#from-concepts-to-torchforge-services">From Concepts to TorchForge Services</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#rl-step-with-torchforge-services">RL Step with TorchForge Services</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-this-matters-traditional-ml-infrastructure-fails">Why This Matters: Traditional ML Infrastructure Fails</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-infrastructure-challenge">The Infrastructure Challenge</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-1-different-resource-needs">Problem 1: Different Resource Needs</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-2-complex-interdependencies">Problem 2: Complex Interdependencies</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-3-the-coordination-challenge">Problem 3: The Coordination Challenge</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#enter-torchforge-rl-native-architecture">Enter TorchForge: RL-Native Architecture</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-makes-this-powerful">What Makes This Powerful</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#automatic-resource-management">Automatic Resource Management</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#independent-scaling">Independent Scaling</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fault-tolerance">Fault Tolerance</a></li>
</ul>
</li>
</ul>
  </nav></div>
    




</div>
</div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  


<style>
.site-footer {
    padding: 20px 40px;
    height: 60px !important;
}

@media screen and (min-width: 768px) {
    .site-footer {
        padding: 20px 40px;
    }
}

.site-footer .privacy-policy {
    border-top: none;
    margin-top: 0px;
}

.site-footer .privacy-policy .copyright {
    padding-top: 0;
}
</style>


<footer class="site-footer">

    <div class="privacy-policy">
      <div class="copyright">
      
        <p>
           Copyright © 2025 Meta Platforms, Inc
        </p>
        
      </div>
    </div>


  </div>
</footer>

<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../_static/img/pytorch-x.svg">
  </div>
</div>
  
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  <script type="application/ld+json">
    {
       "@context": "https://schema.org",
       "@type": "Article",
       "name": "Part 1: RL Fundamentals - Using TorchForge Terminology",
       "headline": "Part 1: RL Fundamentals - Using TorchForge Terminology",
       "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment. Discover tutorials, API references, and guides to help you build and deploy deep learning models efficiently.",
       "url": "/tutorials/zero-to-forge/1_RL_and_Forge_Fundamentals.html",
       "articleBody": "Part 1: RL Fundamentals - Using TorchForge Terminology# Core RL Components in TorchForge# Let\u2019s start with a simple math tutoring example to understand RL concepts with the exact names TorchForge uses: The Toy Example: Teaching Math# graph TD subgraph Example[\"Math Tutoring RL Example\"] Dataset[\"Dataset: math problems\"] Policy[\"Policy: student AI\"] Reward[\"Reward Model: scores answers\"] Reference[\"Reference Model: baseline\"] ReplayBuffer[\"Replay Buffer: stores experiences\"] Trainer[\"Trainer: improves student\"] end Dataset --\u003e Policy Policy --\u003e Reward Policy --\u003e Reference Reward --\u003e ReplayBuffer Reference --\u003e ReplayBuffer ReplayBuffer --\u003e Trainer Trainer --\u003e Policy style Policy fill:#4CAF50,stroke:#fff,stroke-width:2px style Reward fill:#FF9800,stroke:#fff,stroke-width:2px style Trainer fill:#E91E63,stroke:#fff,stroke-width:2px linkStyle default stroke:#888,stroke-width:2px RL Components Defined (TorchForge Names)# Dataset: Provides questions/prompts (like \u201cWhat is 2+2?\u201d) Policy: The AI being trained (generates answers like \u201cThe answer is 4\u201d) Reward Model: Evaluates answer quality (gives scores like 0.95) Reference Model: Original policy copy (prevents drift from baseline) Replay Buffer: Stores experiences (question + answer + score) Trainer: Updates the policy weights based on experiences The RL Learning Flow# # CONCEPTUAL EXAMPLE - see apps/grpo/main.py for GRPO Code def conceptual_rl_step(): # 1. Get a math problem question = dataset.sample() # \"What is 2+2?\" # 2. Student generates answer answer = policy.generate(question) # \"The answer is 4\" # 3. Teacher grades it score = reward_model.evaluate(question, answer) # 0.95 # 4. Compare to original student baseline = reference_model.compute_logprobs(question, answer) # 5. Store the experience experience = Episode(question, answer, score, baseline) replay_buffer.add(experience) # 6. When enough experiences collected, improve student batch = replay_buffer.sample(curr_policy_version=0) if batch is not None: trainer.train_step(batch) # Student gets better! # \ud83d\udd04 See complete working example below with actual TorchForge service calls From Concepts to TorchForge Services# Here\u2019s the key insight: Each RL component becomes a TorchForge service. The toy example above maps directly to TorchForge: graph LR subgraph Concepts[\"RL Concepts\"] C1[\"Dataset\"] C2[\"Policy\"] C3[\"Reward Model\"] C4[\"Reference Model\"] C5[\"Replay Buffer\"] C6[\"Trainer\"] end subgraph Services[\"TorchForge Services (Real Classes)\"] S1[\"DatasetActor\"] S2[\"Generator\"] S3[\"RewardActor\"] S4[\"ReferenceModel\"] S5[\"ReplayBuffer\"] S6[\"RLTrainer\"] end C1 --\u003e S1 C2 --\u003e S2 C3 --\u003e S3 C4 --\u003e S4 C5 --\u003e S5 C6 --\u003e S6 style C2 fill:#4CAF50 style S2 fill:#4CAF50 style C3 fill:#FF9800 style S3 fill:#FF9800 RL Step with TorchForge Services# Let\u2019s look at the example from above again, but this time we would use the names from TorchForge: # Conceptual Example async def conceptual_forge_rl_step(services, step): # 1. Get a math problem - Using actual DatasetActor API sample = await services[\u0027dataloader\u0027].sample.call_one() question, target = sample[\"request\"], sample[\"target\"] # 2. Student generates answer - Using actual Policy API responses = await services[\u0027policy\u0027].generate.route(prompt=question) answer = responses[0].text # 3. Teacher grades it - Using actual RewardActor API score = await services[\u0027reward_actor\u0027].evaluate_response.route( prompt=question, response=answer, target=target ) # 4. Compare to baseline - Using actual ReferenceModel API # Note: ReferenceModel.forward requires input_ids, max_req_tokens, return_logprobs ref_logprobs = await services[\u0027ref_model\u0027].forward.route( input_ids, max_req_tokens, return_logprobs=True ) # 5. Store experience - Using actual Episode structure from apps/grpo/main.py episode = create_episode_from_response(responses[0], score, ref_logprobs, step) await services[\u0027replay_buffer\u0027].add.call_one(episode) # 6. Improve student - Using actual training pattern batch = await services[\u0027replay_buffer\u0027].sample.call_one( curr_policy_version=step ) if batch is not None: inputs, targets = batch loss = await services[\u0027trainer\u0027].train_step.call(inputs, targets) return loss Key difference: Same RL logic, but each component is now a distributed, fault-tolerant, auto-scaling service. Did you realise-we are not worrying about any Infra code here! TorchForge Automagically handles the details behind the scenes and you can focus on writing your RL Algorithms! Why This Matters: Traditional ML Infrastructure Fails# The Infrastructure Challenge# Our simple RL loop above has complex requirements: Problem 1: Different Resource Needs# Component Resource Needs Scaling Strategy Policy (Student AI) Large GPU memory Multiple replicas for throughput Reward Heuristic (Teacher) Small compute CPU or small GPU Trainer (Tutor) Massive GPU compute Distributed training Dataset (Question Bank) CPU intensive I/O High memory bandwidth Problem 2: Complex Interdependencies# graph LR A[\"Policy: Student AI \u0027What is 2+2?\u0027 \u2192 \u0027The answer is 4\u0027\"] B[\"Reward: Teacher Scores answer: 0.95\"] C[\"Reference: Original Student Provides baseline comparison\"] D[\"Replay Buffer: Notebook Stores: question + answer + score\"] E[\"Trainer: Tutor Improves student using experiences\"] A --\u003e B A --\u003e C B --\u003e D C --\u003e D D --\u003e E E --\u003e A style A fill:#4CAF50 style B fill:#FF9800 style C fill:#2196F3 style D fill:#8BC34A style E fill:#E91E63 Each step has different: Latency requirements: Policy inference needs low latency (each episode waits), training can batch multiple episodes together Scaling patterns: Need N policy replicas to keep trainer busy, plus different sharding strategies (tensor parallel for training vs replicated inference) Failure modes: Any component failure cascades to halt the entire pipeline (TorchForge prevents this with automatic failover) Resource utilization: GPUs for inference/training, CPUs for data processing Problem 3: The Coordination Challenge# Unlike supervised learning where you process independent batches, RL requires coordination: # While this does work, it creates bottlenecks and resource waste def naive_rl_step(): # Policy waits idle while reward model works response = policy_model.generate(prompt) # GPU busy reward = reward_model.evaluate(prompt, response) # Policy GPU idle # Training waits for single episode loss = compute_loss(response, reward) # Batch size = 1, inefficient # Everything stops if any component fails if policy_fails or reward_fails or trainer_fails: entire_system_stops() Enter TorchForge: RL-Native Architecture# TorchForge solves these problems by treating each RL component as an independent, distributed unit - some as fault-tolerant services (like Policy inference where failures are easy to handle), others as actors (like Trainers where recovery semantics differ) Let\u2019s see how core RL concepts map to TorchForge components (you\u2019ll notice a mix of .route() for services and .call_one() for actors - we cover when to use each in Part 2): Quick API Reference: (covered in detail in Part 2: Service Communication Patterns) .route() - Send request to any healthy replica in a service (load balanced) .call_one() - Send request to a single actor instance .fanout() - Send request to ALL replicas in a service async def real_rl_training_step(services, step): \"\"\"Single RL step using verified TorchForge APIs\"\"\" # 1. Environment interaction - Using actual DatasetActor API sample = await services[\u0027dataloader\u0027].sample.call_one() prompt, target = sample[\"request\"], sample[\"target\"] responses = await services[\u0027policy\u0027].generate.route(prompt) # 2. Reward computation - Using actual RewardActor API score = await services[\u0027reward_actor\u0027].evaluate_response.route( prompt=prompt, response=responses[0].text, target=target ) # 3. Get reference logprobs - Using actual ReferenceModel API # Note: ReferenceModel requires full input_ids tensor, not just tokens input_ids = torch.cat([responses[0].prompt_ids, responses[0].token_ids]) ref_logprobs = await services[\u0027ref_model\u0027].forward.route( input_ids.unsqueeze(0), max_req_tokens=512, return_logprobs=True ) # 4. Experience storage - Using actual Episode pattern from GRPO episode = create_episode_from_response(responses[0], score, ref_logprobs, step) await services[\u0027replay_buffer\u0027].add.call_one(episode) # 5. Learning - Using actual trainer pattern batch = await services[\u0027replay_buffer\u0027].sample.call_one( curr_policy_version=step ) if batch is not None: inputs, targets = batch # GRPO returns (inputs, targets) tuple loss = await services[\u0027trainer\u0027].train_step.call(inputs, targets) # 6. Policy synchronization - Using actual weight update pattern await services[\u0027trainer\u0027].push_weights.call(step + 1) await services[\u0027policy\u0027].update_weights.fanout(step + 1) return loss Key insight: Each line of RL pseudocode becomes a service call. The complexity of distribution, scaling, and fault tolerance is hidden behind these simple interfaces. What Makes This Powerful# Automatic Resource Management# responses = await policy.generate.route(prompt=question) answer = responses[0].text # responses is list[Completion] TorchForge handles behind the scenes: Routing to least loaded replica GPU memory management Batch optimization Failure recovery Auto-scaling based on demand Independent Scaling# from forge.actors.generator import Generator as Policy from forge.actors.replay_buffer import ReplayBuffer from forge.actors.reference_model import ReferenceModel from forge.actors.trainer import RLTrainer from apps.grpo.main import DatasetActor, RewardActor, ComputeAdvantages from forge.data.rewards import MathReward, ThinkingReward import asyncio import torch model = \"Qwen/Qwen3-1.7B\" group_size = 1 ( dataloader, policy, trainer, replay_buffer, compute_advantages, ref_model, reward_actor, ) = await asyncio.gather( # Dataset actor (CPU) DatasetActor.options(procs=1).as_actor( path=\"openai/gsm8k\", revision=\"main\", data_split=\"train\", streaming=True, model=model, ), # Policy service with GPU Policy.options(procs=1, with_gpus=True, num_replicas=1).as_service( engine_config={ \"model\": model, \"tensor_parallel_size\": 1, \"pipeline_parallel_size\": 1, \"enforce_eager\": False }, sampling_config={ \"n\": group_size, \"max_tokens\": 16, \"temperature\": 1.0, \"top_p\": 1.0 } ), # Trainer actor with GPU RLTrainer.options(procs=1, with_gpus=True).as_actor( # Trainer config would come from YAML in real usage model={\"name\": \"qwen3\", \"flavor\": \"1.7B\", \"hf_assets_path\": f\"hf://{model}\"}, optimizer={\"name\": \"AdamW\", \"lr\": 1e-5}, training={\"local_batch_size\": 2, \"seq_len\": 2048} ), # Replay buffer (CPU) ReplayBuffer.options(procs=1).as_actor( batch_size=2, max_policy_age=1, dp_size=1 ), # Advantage computation (CPU) ComputeAdvantages.options(procs=1).as_actor(), # Reference model with GPU ReferenceModel.options(procs=1, with_gpus=True).as_actor( model={\"name\": \"qwen3\", \"flavor\": \"1.7B\", \"hf_assets_path\": f\"hf://{model}\"}, training={\"dtype\": \"bfloat16\"} ), # Reward actor (CPU) RewardActor.options(procs=1, num_replicas=1).as_service( reward_functions=[MathReward(), ThinkingReward()] ) ) TorchForge Components: Services vs Actors TorchForge has two types of distributed components: Services: Multiple replicas with automatic load balancing (like Policy, RewardActor) Actors: Single instances that handle their own internal distribution (like RLTrainer, ReplayBuffer) We cover this distinction in detail in Part 2, but for now this explains the scaling patterns: Policy service: num_replicas=8 for high inference demand RewardActor service: num_replicas=16 for parallel evaluation RLTrainer actor: Single instance with internal distributed training Fault Tolerance# # If a policy replica fails: responses = await policy.generate.route(prompt=question) answer = responses[0].text # -\u003e TorchForge automatically routes to healthy replica # -\u003e Failed replica respawns in background # -\u003e No impact on training loop # If reward service fails: score = await reward_actor.evaluate_response.route( prompt=question, response=answer, target=target ) Retries on different replica automatically Graceful degradation if all replicas fail System continues (may need application-level handling) This is fundamentally different from monolithic RL implementations where any component failure stops everything! In the next Section, we will go a layer deeper and learn how ForgeServices work. Continue to Part 2 here",
       "author": {
         "@type": "Organization",
         "name": "PyTorch Contributors",
         "url": "https://pytorch.org"
       },
       "image": "../../_static/img/pytorch_seo.png",
       "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "/tutorials/zero-to-forge/1_RL_and_Forge_Fundamentals.html"
       },
       "datePublished": "2023-01-01T00:00:00Z",
       "dateModified": "2023-01-01T00:00:00Z"
     }
 </script>
  <script>
    // Tutorials Call to action event tracking
    $("[data-behavior='call-to-action-event']").on('click', function () {
      fbq('trackCustom', "Download", {
        tutorialTitle: $('h1:first').text(),
        downloadLink: this.href,
        tutorialLink: window.location.href,
        downloadTitle: $(this).attr("data-response")
      });
      if (typeof gtag === 'function') {
        gtag('event', 'click', {
          'event_category': $(this).attr("data-response"),
          'event_label': $("h1").first().text(),
          'tutorial_link': window.location.href
        });
      }
    });
  </script>
  
  </body>
</html>