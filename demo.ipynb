{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed6165f4-0038-40d3-bf65-419fcf61af24",
   "metadata": {},
   "source": [
    "# Intro to Forge\n",
    "\n",
    "Forge is a PyTorch-native framework designed for rapid experimentation and large-scale training of Reinforcement Learning (RL) algorithms with Large Language Models (LLMs). It's designed to:\n",
    "- Express RL algorithms as naturally as psuedocode, while scaling seamlessly across clusters\n",
    "- Support varying degrees of asynchrony - from fully synchronous/on-policy, to fully asynchronous/off-policy training\n",
    "- Separate infrastructural concerns from algorithmic implementation\n",
    "- Bias towards composable, reusable components that can be mixed and matched for different RL approaches\n",
    "\n",
    "Forge is built on top of proven components:\n",
    "- **[Monarch](https://github.com/meta-pytorch/monarch)** - PyTorch-native single-controller framework\n",
    "- **[torchtitan](https://github.com/pytorch/torchtitan)** - PyTorch-native large-scale LLM training platform\n",
    "- **[vLLM](https://github.com/vllm-project/vllm)** - A high-throughput, memory efficient inference and serving engine for LLMs\n",
    "\n",
    "Our mission is to accelerate innovation in reinforcement learning by empowering researchers and developers to explore new RL algorithms and infrastructure techniques. Whether you're designing novel training methods or optimizing distributed systems, Forge provides a foundation to build upon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24de9912-ed10-4729-9616-2f85bbf64e43",
   "metadata": {},
   "source": [
    "## Brief Intro to Monarch\n",
    "Before diving into Forge, we need to first establish the foundation. Forge is built on top of Monarch, PyTorch's native single-controller framework for distributed execution.\n",
    "\n",
    "Forge builds many of its abstractions on top of Monarch, so it's worth introducing a few of its key concepts first. The following sections borrow from Monarch's Getting Started Guide (not public yet).\n",
    "\n",
    "### Defining an Actor\n",
    "At its core, Monarch uses [actors](https://en.wikipedia.org/wiki/Actor_model) as a way to create multi-machine programs. Actors are Python objects that expose a number of endpoint functions. These functions can be called by other actors in the system and their responses gathered asynchronously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "334ff5d6-bf9f-4b53-a04e-b488083a8101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from monarch.actor import Actor, endpoint, this_proc\n",
    "\n",
    "class Counter(Actor):\n",
    "    def __init__(self, initial_value: int):\n",
    "        self.value = initial_value\n",
    "\n",
    "    @endpoint\n",
    "    def increment(self) -> None:\n",
    "        self.value += 1\n",
    "\n",
    "    @endpoint\n",
    "    def get_value(self) -> int:\n",
    "        return self.value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2815f7-ad6f-4928-b262-033c9b5cb847",
   "metadata": {},
   "source": [
    "The decorator `@endpoint` specifies functions of the Actor that can be called remotely from other actors.\n",
    "\n",
    "### Spawning An Actor In The Local Process\n",
    "\n",
    "We spawn actors in the current running process like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9e22453-d877-4334-8d80-b3bc1de85455",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter: Counter = this_proc().spawn(\"counter\", Counter, initial_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a9aa84-2ef4-4961-9173-4fee73c065c5",
   "metadata": {},
   "source": [
    "`this_proc()` is a handle to a process, giving us direct control over where an actor runs. Monarch is very literal about where things are run, so that code can be written in the most efficient way. \n",
    "\n",
    "### Sending A Simple Message\n",
    "Once an actor is spawned, we can send messages to the actor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d20ada2-9084-4439-bd9b-e95881cf7009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter value: 0\n"
     ]
    }
   ],
   "source": [
    "from monarch.actor import Future\n",
    "\n",
    "fut: Future[int] = counter.get_value.call_one()\n",
    "\n",
    "value = await fut\n",
    "\n",
    "print(f\"Counter value: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd15594-380a-44a1-977c-c536b6ae3a9c",
   "metadata": {},
   "source": [
    "Here we invoke the `get_value` message, returning 0, the current value of the Counter. `call_one` here is referred to as an \"adverb\" because it modified how results of the endpoint are handled. `call_one` just invokes a single actor and gets its value.\n",
    "\n",
    "Notice that the return value is a `Future[int]` - the message is sent asynchronously, letting the sender do other things before it needs the reply. We can `await` on the result.\n",
    "\n",
    "### Multiple Actors at Once\n",
    "Monarch scales to thousands of machines because of its ability to broadcast a single message to many actors at once, rather than send many point-to-point messages.\n",
    "\n",
    "Monarch expresses broadcasted communication by organizing actors into a `Mesh` - a multi-dimensional container with named dimensions. An example cluster may have dimensions `{\"hosts\": 32, \"gpus\": 8}`. To create a mesh of actors, we'll create a mesh of processes and spawn an actor on them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4349a0c4-161c-4d68-9d97-202b650e344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monarch.actor import ProcMesh, this_host\n",
    "\n",
    "procs: ProcMesh = this_host().spawn_procs(per_host={\"gpus\": 8})\n",
    "counters: Counter = procs.spawn(\"counters\", Counter, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202a8126-2e45-4074-a2ba-87e12d2f06dc",
   "metadata": {},
   "source": [
    "### Broadcasting Messages\n",
    "Now messages can be sent to all actors in the mesh:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1395ba9-c47a-4902-bea2-320bd1144fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ValueMesh({gpus=8})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await counters.increment.call()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e2f5da-1840-49f5-b187-47be6d4b185d",
   "metadata": {},
   "source": [
    "Note that here, we use the `call()` adverb. You will see other adverbs in Monarch code as well:\n",
    "- `call_one()` - invoke a single actor and get its value (what we saw before)\n",
    "- `choose()` - randomly invoke a single actor and gets its value from within a mesh of actors\n",
    "- `call()` - invoke all actors in an actor mesh, and return its values as a `ValueMesh` \n",
    "- `broadcast()` - fire-and-forget all actors in an actor mesh\n",
    "- `stream()` - invoke all actors and return its values as an iterator\n",
    "\n",
    "There's much more to cover with Monarch, but these foundations provide the building blocks needed to understand how Forge creates its RL-specific services on top of this distributed actor system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924b1514-b10c-4a4e-bc11-222f3f2a2933",
   "metadata": {},
   "source": [
    "## Forge Services\n",
    "Forge introduces *Services* - a higher-level abstraction built on top of Monarch actors. Services handle all the operational complexity of managing distributed ActorMeshes: spawning actors across nodes, fault tolerance, load balancing, and intelligent routing.\n",
    "\n",
    "### Creating a Forge Service\n",
    "Creating a Forge service requires minimal changes to actors like we've created above. You replace your Actor base with a ForgeActor, and change how you spawn the actor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "248530c1-3cbc-44b1-aa80-aab335280870",
   "metadata": {},
   "outputs": [],
   "source": [
    "from forge.controller import ForgeActor\n",
    "from forge.controller.service import ServiceConfig, spawn_service\n",
    "from monarch.actor import endpoint\n",
    "\n",
    "\n",
    "class ForgeCounter(ForgeActor):\n",
    "    def __init__(self, initial_value: int):\n",
    "        self.value = initial_value\n",
    "\n",
    "    @endpoint\n",
    "    def increment(self) -> int:\n",
    "        self.value += 1\n",
    "        return self.value\n",
    "\n",
    "    @endpoint\n",
    "    def get_value(self) -> int:\n",
    "        return self.value\n",
    "\n",
    "    @endpoint\n",
    "    async def reset(self):\n",
    "        self.value = 0\n",
    "\n",
    "    @endpoint\n",
    "    def fail():\n",
    "        raise ValueError()\n",
    "\n",
    "\n",
    "counter_service = await spawn_service(\n",
    "    ServiceConfig(procs_per_replica=1, num_replicas=4),\n",
    "    ForgeCounter,\n",
    "    initial_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f905101-9a69-4532-8e88-711c83ed1570",
   "metadata": {},
   "source": [
    "Here, we've created a simple \"Counter service\" with 4 replicas, each running on 1 process.\n",
    "\n",
    "### Service Adverbs: Operating at the Replica Level\n",
    "Services introduce new adverbs that operate at the replica level, not individual actors. Since replicas can be spawned across multiple processes, each replica is essentially an ActorMesh in Monarch terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07a02047-f29a-47bf-a077-6bd5c2976cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# choose() - routes to one replica (load balanced, and which may contain multiple actors)\n",
    "await counter_service.increment.choose()\n",
    "\n",
    "# call() - runs on ALL replicas\n",
    "results = await counter_service.increment.call()\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a08b5a5-0180-4e0d-80b4-cc0620c510b4",
   "metadata": {},
   "source": [
    "Key distinction:\n",
    "- Monarch's `choose()` picks a single actor from an `ActorMesh`\n",
    "- Forge's `choose()` picks a single replica (which could be an entire `ActorMesh` of actors)\n",
    "\n",
    "This abstraction lets you think in terms of logical compute units (replicas) rather than individual processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac9c7dc-42b5-4e10-a0ae-34916fc40360",
   "metadata": {},
   "source": [
    "### Load Balancing in Action\n",
    "Services handle load balancing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11181a5a-5692-4163-a96a-151d9b075454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increment on different replicas:\n",
      "Call 0: Counter value = 1\n",
      "Call 1: Counter value = 1\n",
      "Call 2: Counter value = 1\n",
      "Call 3: Counter value = 1\n",
      "Call 4: Counter value = 2\n",
      "Call 5: Counter value = 2\n",
      "Call 6: Counter value = 2\n",
      "Call 7: Counter value = 2\n"
     ]
    }
   ],
   "source": [
    "await counter_service.reset.call()\n",
    "print(\"Increment on different replicas:\")\n",
    "for i in range(8):\n",
    "    result = await counter_service.increment.choose()\n",
    "    print(f\"Call {i}: Counter value = {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c9334f-4db7-4cde-8ef2-d8e66a26d21b",
   "metadata": {},
   "source": [
    "Each replica maintains its own state, and requests are distributed evenly.\n",
    "\n",
    "### Sticky Session for Stateful Operations\n",
    "When you need to interact with the same replica consistently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "453ec452-8a71-44ca-8afe-4393270356a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "2\n",
      "1\n",
      "Final value on this replica: 0\n"
     ]
    }
   ],
   "source": [
    "# Use sticky sessions to stay on one replica\n",
    "async with counter_service.session():\n",
    "    await counter_service.reset.choose()\n",
    "    print(await counter_service.increment.choose())\n",
    "    print(await counter_service.increment.choose())\n",
    "    print(await counter_service.increment.choose())\n",
    "          \n",
    "    final_value = await counter_service.get_value.choose()\n",
    "    print(f\"Final value on this replica: {final_value}\")  # 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1864330d-a19b-4fb0-b810-257a17b6e56b",
   "metadata": {},
   "source": [
    "Notes, things I want to show:\n",
    "1. New adverbs, you can do `choose()` which runs on a **replica**, not an individual actor and you can run `call()` which runs on **all replicas** (this is subject to change as I acknowledge it's confusing to re-use the adverbs from base Monarch)\n",
    "3. When you do `choose()` normally, it will do a round robin load balancing\n",
    "4. You can run with sticky sessions, with the context manager:\n",
    "```\n",
    "with counter_service.session:\n",
    "    await counter_service.increment.choose()\n",
    "```\n",
    "which lets you \n",
    "5. Whenever the service encounters an actor failure, it will mark it as unhealthy and recover it automatically\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44344bab-edcd-4851-98e4-59d8f9a4f3d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0758b20f-11e2-4733-b675-9520b133158f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c622ed81-8fbc-4bd6-95f8-11a5df682711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from forge.actors.policy import Policy, PolicyConfig, SamplingOverrides, WorkerConfig\n",
    "from forge.actors.replay_buffer import ReplayBuffer\n",
    "from forge.controller.actor import ForgeActor\n",
    "from forge.controller.service import ServiceConfig, shutdown_service, spawn_service\n",
    "from forge.data.rewards import MathReward, ThinkingReward\n",
    "\n",
    "from apps.grpo.main import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcafffd7-f8c0-4b11-9f5b-cbbcf457a3af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
