# GRPO training configuration

model:
  name: "meta-llama/Llama-3.1-8B-Instruct"

titan_model:
  name: "llama3"
  flavor: "8B"

training:
  learning_rate: 1e-5
  beta: 0.1
  batch_size: 4
  max_policy_age: 1
  group_size: 1
  max_tokens: 16

dataset:
  path: "openai/gsm8k"
  config_name: "main"
  split: "train"
  streaming: true

services:
  dataloader:
    procs_per_replica: 1
    num_replicas: 1
    with_gpus: false
  policy:
    procs_per_replica: 1
    num_replicas: 1
    with_gpus: true
  trainer:
    procs_per_replica: 1
    num_replicas: 1
    with_gpus: true
  replay_buffer:
    procs_per_replica: 1
    num_replicas: 1
    with_gpus: false
  compute_advantages:
    service:
      procs_per_replica: 1
      num_replicas: 1
      with_gpus: false
    gamma: 0.99
    lambda_: 0.95
  ref_model:
    procs_per_replica: 1
    num_replicas: 1
    with_gpus: true
  reward_actor:
    procs_per_replica: 1
    num_replicas: 1
    with_gpus: false

logging:
  backend: "wandb"
  project: "grpo-training"
  frequency: 1

training_loop:
  rollout_log_frequency: 10
  training_log_frequency: 10
